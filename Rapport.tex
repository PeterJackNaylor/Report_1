\documentclass{article}
\usepackage[utf8]{inputenc}
%%\usepackage[francais]{babel}
\usepackage[T1]{fontenc}
\usepackage{graphicx}    
%\usepackage{eurosym}
\usepackage{verbatim}      
\usepackage{amsmath, amsthm}                             
\usepackage{latexsym}                               
\usepackage{amssymb}
\usepackage{tabularx}
\usepackage{setspace}
\usepackage{listings}
\usepackage{geometry}
\usepackage{fancyhdr}
%\usepackage{enumitem}
\usepackage{colortbl}
%\usepackage[dvipsnames]{xcolor}
\usepackage{booktabs} 
%\usepackage{moreverb}

\DeclareMathAlphabet{\mathonebb}{U}{bbold}{m}{n}
\newcommand{\one}{\ensuremath{\mathonebb{1}}}

\usepackage{color}
%\usepackage{multirow}
%\usepackage{float}
\definecolor{gris25}{gray}{0.75}
\usepackage{colortbl}
\usepackage{fancyhdr}
\usepackage{amsmath,amsfonts,amssymb}
%\usepackage{titlesec}
%\usepackage{supertabular}
\usepackage{longtable}

\usepackage{caption}
\usepackage{subcaption}


\usepackage{listings}
\definecolor{dkgreen}{rgb}{0,0.4,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

%\usepackage{algorithm2e}

\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=blue,
}
 
\urlstyle{same}

\definecolor{dkyellow}{cmyk}{0, 0, 0.2, 0}
\lstset{
  language=Python,                % the language of the code
  basicstyle= \footnotesize,      % the size of the fonts that are used for the code
  numbers=left,                   % where to put the line-numbers
  numberstyle=\tiny\color{gray},  % the style that is used for the line-numbers
  stepnumber=2,                   % the step between two line-numbers. If it's 1, each line 
                                  % will be numbered
  showspaces=false,               % show spaces adding particular underscores
  showtabs=false,                 % show tabs within strings adding particular underscores
  frame=single,                   % adds a frame around the code
  rulecolor=\color{black},        % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. commens (green here))
  tabsize=2,                      % sets default tabsize to 2 spaces
  captionpos=b,                   % sets the caption-position to bottom
  breaklines=true,                % sets automatic line breaking
  breakatwhitespace=false,        % sets if automatic breaks should only happen at whitespace
  keywordstyle=\color{blue},      % keyword style
  commentstyle=\color{dkgreen},   % comment style
  stringstyle=\color{mauve},       % string literal style
  backgroundcolor=\color{white},      % choose the background color. You must add \usepackage{color}
}

\usepackage{array}
\newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{R}[1]{>{\raggedleft\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}

\usepackage{xcoffins}
\NewCoffin\tablecoffin
\NewDocumentCommand\Vcentre{m}
  {%
    \SetHorizontalCoffin\tablecoffin{#1}%
    \TypesetCoffin\tablecoffin[l,vc]%
  }



\begin{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{titlepage}

%  \begin{center} 
%    \textsc{ENSAE ParisTech}\\
%    ---\\
%    AnnÃ©e 2013--2014
%  \end{center}
  
\begin{center}
\includegraphics[width=0.3\textwidth]{Mines_ParisTech.png} 
\includegraphics[width=0.3\textwidth]{CURIE.jpg}
\includegraphics[width=0.3\textwidth]{INSERM.jpg}
\end{center}

\vspace{\stretch{1}}
 
\noindent
\hrulefill
  \begin{center} \bfseries\Huge
Towards image-based cancer signatures from histopathology data
  \end{center}
  \begin{center} \huge
   First year report
  \end{center}
\hrulefill 
  
  \vspace{\stretch{2}}
   \begin{center}  \large
\textit{Supervisor} : \textsc{T. Walter and F. Reyal}. \\
\textit{Units:} \textsc{Center for Computational Biology and UMR900}

   \end{center}
     
  \vspace{\stretch{3}}
  \begin{center} \Large
  Peter \textsc{Naylor}
  \end{center}

  \vspace{\stretch{4}}

  \begin{center}  \large
    June 2016
  \end{center}

\end{titlepage}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




\newpage
\tableofcontents
\newpage

\section{Introduction}

\subsection{Context}

\subsection{PhD subject}

\section{November 2015 - January 2016: MitoCheck Project}

\section{January 2016 - April 2016: Camelyon2016 challenge}

This Challenge is organized in conjunction with and with the support of the 2016 IEEE International Symposium on Biomedical Imaging  (ISBI-2016) and this the first challenge using whole-slide images in histopathology. This challenge fitted particularly well with my PhD time table as the data used in this challenge is very similar to the data acquired by F. Reyal. Our final ranking was not very satisfying as we did not achieve good results. This work was done with the help of V. Machairas, T. Walter and E. Decenciere. A website was made for the purpose of this challenge, \url{http://camelyon16.grand-challenge.org/home/}.

\subsection{Context}
The goal of this challenge is to evaluate new and existing algorithms for automated detection of metatases in hematoxylin and eosin (HE) stained whole-slide images of lymph node sections, see figure \ref{LymphNode} This task has a high clinical relevance but requires large amounts of reading time from pathologists. Therefore, a successful solution would hold great promise to reduce the workload of the pathologists while at the same time reduce the subjectivity in diagnosis. The Camelyon2016 challenge will focus on sentinel lymph nodes of breast cancer patients and 2 large datasets have been provided from both the Radboud University Medical Center (Nijmegen, the Netherlands), as well as the University Medical Center Utrecht (Utrecht, the Netherlands). The focus on lymph nodes of breast cancer patients is not arbitrary, lymph node metastases occur in most cancer types (e.g. breast, prostate, colon). Lymph nodes are small glands that filter lymph, the fluid that circulates through the lymphatic system. The lymph nodes in the underarm are the first place breast cancer is likely to spread. Metastatic involvement of lymph nodes is one of the most important prognostic variables in breast cancer. Prognosis is poorer when cancer has spread to the lymph nodes.
\subsubsection*{Data}
The data in this challenge contains a total of 400 whole-slide images (WSIs) of sentinel lymph node from two independent datasets collected in Radboud University Medical Center (Nijmegen, the Netherlands), and the University Medical Center Utrecht (Utrecht, the Netherlands). The training dataset consists of 270 WSIs of lymph node (160 Normal and 110 containing metastases). WSI are generally stored in a multi-resolution pyramid structure. WSI contain multiple downsampled versions of the original image. Each image in the pyramid is stored as a series of tiles, this file structure is to facilitate rapid retrieval of subregions of the image as one could not even open one at the highest resolution, see figure \ref{fig: Pyramid}. These compression technics are similar to those used by Google Earth and even use the same compression format, jpeg2000. If uncompressed, the original image is roughly 65 GB and is an image of size 100 000 x 200 000 pixels.

\begin{figure}[!ht]
\centering
\includegraphics[width=0.8\textwidth]{pyramid.png}
\caption{Pyramid data Structure}
\textit{Between 8 and 10 different resolutions}
\label{fig: Pyramid}
\end{figure}
Uncompressed one image can reach up to 65 GB, the WSI on the highest resolution had size 96256 x 218624 pixels and the lowest resolution had 188 x 427 pixels.


\subsection{Classification problem}
There were two evaluations and therefore two distinct scoreboards for this challenge. The first is slide based and can be seen as a binary classification, given a Whole-slide Images (WSI) we had to give a confidence score that this WSI contained metastases. The final score for this evaluation was given by the area under the curve (or ROC curve) asserted over 130 test slides. The second was a lesion-based evaluation, this evaluation was aimed to asses the metastases detection within a given slide. This within slide evaluation was measured vi a free-response receiver operating characteristic (FROC). This is similar to ROC analysis, except that the false positive rate on the x-axis is replaced by the average number of false positives per image. For this challenge, our detection will be considered a true positive, if the location of the detected region is within the annotated ground truth lesion. The FROC curve is defined as the plot of sensitivity versus the average number of false-positives per image. 

Due to limited time, we tackled these two evaluations as a pixel classification in supervised setting. Each pixel is described by a vector of features $x \in \mathbb{R}^P$. The training set is composed of a set of such vectors $x^T$,combined in the data matrix $X \in \mathbb{R}^{N \times P}$ and the corresponding labels $Y \in \{0,1\}^N$, provided by the challenge annotators. 
%The concatenation of all vectors is denoted by $X \in
The computational steps and design choices that had to be made can be categorized as follows: 
\begin{enumerate}
	\item Pre-processing of the stained whole-slide images.
	% Feature  extraction. Here, we used a pannel of color and texture
    %     descriptors, evaluated on superpixel regions.
	%\item Sampling strategies in order to derive a reasonably
    %      sized training data set. 
         \item Classification method: here we tested and adapted
           Random Forests and Support Vector Machines. 
         \item Post-processing of the probability map.
\end{enumerate}
%%---------------------------------------
%%---------------------------------------

\begin{figure}[!ht]
\centering
\includegraphics[width=0.4\textwidth]{Booby.png}
\caption{Lymph nodes}
\label{LymphNode}
\end{figure}

\begin{figure}[!ht]
\centering
\includegraphics[width=\textwidth]{Camelyon16.png}
\caption{Official logo}
\label{Ol}
\end{figure}
\subsection{Work pipeline}
Some of the decisions made in this section where a necessity due to the technological difficulties caused by the type of data. In figure \ref{PipelineCam}, I expose a graphic summarising the pre-processing step to the machine learning core. The pre-processing step is not included in this graphic.



\subsubsection*{Pre-processing}

In order to access relevant information in such a tiff file, we had to think careful as how to segment the whole image to have relevant patches, these patches were a necessity to process the information contained in the slide (Memory constraints). As a WSI is mostly composed of white, processing only the patches contain tissue were restrained. The method used relied on a threshold segmentation of the WSI at a low resolution in order to cover the whole image. Once the tissue areas were found, we extracted small patches at a very high resolution (resolution number 2) randomly from the WSI. 300 to 400 images of size 1000 x 1000 were extracted on average per WSI. We then applied color deconvolution \cite{deconvolution} to the smaller images in order to obtain a physicologically relevant representation
of the color information.  This was done in order to reduce the
computational burden for the subsequent steps.
%A set of 100 \textit{Superpixel-Adaptive Features} (SAF) were used to
%describe each pixel of the train and test image databases. As
%presented in \cite{saf}, these features are well suited for
%segmentation purposes as they are computed on superpixels, i.e. on a
%\textit{computational support} which adapts to the image
%content. 
%Here, we used \textit{waterpixels} \cite{waterpixels}, as they feature
%good adherence to real object boundaries and they are very fast to
%compute. In particular, this allowed us to calculate several
%superpixel partitions, therefore capturing information at different
%scales. 

On each image, we calculated a large panel of different features describing color
and texture of the images. For this, different operators were applied
on the images: identity; a set of operators from Mathematical
Morphology: erosion, opening, top hat and morphological gradient (different
sizes of structuring elements with V6 neighborhood); Haralick texture
features (averaged on all directions); and a family of features based
on Gaussians: difference of gaussians (faster approximation of the
laplacian), eigenvalues of the structure tensor, eigenvalues of
hessian of gaussian. 

We evaluated these features on superpixel regions: we first calculated
a partition of the image into superpixels. Here, we used
\textit{waterpixels} \cite{waterpixels}, as they feature good
adherence to real object boundaries and they are very fast to
compute.  In particular, this allowed us to calculate several
superpixel partitions with different size parameters, therefore capturing
information at different scales. The features were then evaluated on
the superpixel regions (average values) at the different
scales. Altogether, we obtained 100 features for each pixel in this step. 

%The partition into waterpixels (with a given set of parameters values)
%was computed once and each pixel was assigned
%the average pixel value within the superpixel it belonged to. 
%
%In order to
%capture multiscale information, we repeated the process with
%waterpixels of different sizes ($step \in \left[ 15,20, 30\right]
%pixels$).\\ 
%
%%---------------------------------------
%%---------------------------------------
\subsubsection*{Classification model}
%%---------------------------------------
%%---------------------------------------
We investigated two classification methods: Random Forests and Support
Vector Machines with RBF kernels. The particularity of the
classification task was an extremely large number of samples ($N \sim  10^{10}$).
Consequently, we could not simply apply the learning algorithms on the
entire data set.  
\begin{enumerate}
\item {\it Random Forests (RF):} Having access to a very large number of
  samples allows us to modify the standard RF procedure. Random
  forests work best, if the individual trees are different from each
  other and cover ``different aspects'' of the data. This is normally
  achieved by boosting, and by randomly drawing the features to be
  considered. With the amount of annotated data we have here, we can
  afford presenting different data to each tree. We therefore generate
  different (but stratified) training sets for each tree of the Random
  Forest.  
\item {\it Support Vector Machines (SVM):} Training with large number
  of samples is generally problematic for non-liner SVM. We therefore
  downsampled the data presented to the classifier. In order to
  properly sample the feature space, we designed a hierarchical
  strategy, where we first apply k-means to each slide, and keep only
  a few representing data points for each cluster. This allowed us
  then to learn an SVM with and RBF kernel. 
\end{enumerate}

Once we have a trained classifier, this allowed us to predict on a WSI (via down-sampling) and to obtain probability maps corresponding (hopefully) to pixel based confidence map of each pixel belonging to a metastasis. Given the results on the cross-validation we choose a Random Forest model as it outperformed on F1-score metric and in accuracy. Also, the prediction probability maps on most slides were a lot less noisy than the ones acquired by the Support Vector Machine. The results and and parameter tuning are given in table \ref{cross-val}.

\subsubsection*{Post-processing}

Once we have the probability map of a WSI at a lower resolution we have to decide how to extract the information to better suit the two different tasks. One the one hand, for the slide base evaluation, as we choose a RF model, we could easily take the maximum value of the probability map as the confidence score of this WSI containing metastasis. On the other hand, for the lesion-based evaluation, it was difficult as we had to detect each distinct metastasis, but also not miss as little as possible. We proceeded as the following: we smoothed the image by applying a gaussian filter


\section{May 2016 and future work}



%\begin{figure}[!ht]
%\centering
%\includegraphics[width=\textwidth]{}
%\caption{}
%\label{}
%\end{figure}


\newpage

\begin{thebibliography}{9}

\bibitem{OriginalPaper} Thomas Bühler and Matthias Hein from Saarland University, Germany, \textit{Spectral Clustering based on the graph $p$-Laplacian}. ICML 2009.

\bibitem{deconvolution}
Quantification of histochemical staining by color deconvolution
Ruifrok, A C and Johnston, D A
In: Analytical and quantitative cytology and histology, 2001, 23(4), pp.291--299\\

\bibitem{waterpixels}
Waterpixels.
Machairas, V., Faessel, M., C\'ardenas-Pe\~na, D., Chabardes, T., Walter, T., Decenci\`ere, E..
In: IEEE Transactions on Image Processing, Institute of Electrical and Electronics Engineers, 2015, 24 (11), pp.3707-3716.\\

\bibitem{saf}
New General Features Based on Superpixels for Image Segmentation Learning.
Machairas, V.,T. Baldeweck T., Walter, T., Decenci\`ere, E..
In: International Symposium on Biomedical Imaging, Apr. 2016, Prague, Czech Republic.\\

\bibitem{breiman}
Random Forests.
Breiman, L..
In: Machine Learning, vol. 45, no. 1, pp. 5-32, Oct. 2001.

\end{thebibliography}



\end{document}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%